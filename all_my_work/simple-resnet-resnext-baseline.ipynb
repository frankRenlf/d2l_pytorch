{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "involved-eight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T11:06:13.951732Z",
     "iopub.status.busy": "2022-03-01T11:06:13.950941Z",
     "iopub.status.idle": "2022-03-01T11:06:16.021312Z",
     "shell.execute_reply": "2022-03-01T11:06:16.020406Z",
     "shell.execute_reply.started": "2022-03-01T06:40:50.469596Z"
    },
    "papermill": {
     "duration": 2.093473,
     "end_time": "2022-03-01T11:06:16.021501",
     "exception": false,
     "start_time": "2022-03-01T11:06:13.928028",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-20T12:31:21.865902Z",
     "start_time": "2023-08-20T12:31:21.811178Z"
    }
   },
   "outputs": [],
   "source": [
    "# 首先导入包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "# This is for the progress bar.\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "exact-depth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T11:06:16.061433Z",
     "iopub.status.busy": "2022-03-01T11:06:16.060605Z",
     "iopub.status.idle": "2022-03-01T11:06:16.110137Z",
     "shell.execute_reply": "2022-03-01T11:06:16.109702Z",
     "shell.execute_reply.started": "2022-03-01T06:15:21.008174Z"
    },
    "papermill": {
     "duration": 0.070996,
     "end_time": "2022-03-01T11:06:16.110332",
     "exception": false,
     "start_time": "2022-03-01T11:06:16.039336",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-20T12:31:21.874075Z",
     "start_time": "2023-08-20T12:31:21.815594Z"
    }
   },
   "outputs": [],
   "source": [
    "# 看看label文件长啥样\n",
    "labels_dataframe = pd.read_csv('../data/classify-leaves/train.csv')\n",
    "# labels_dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fundamental-continent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T11:06:16.168289Z",
     "iopub.status.busy": "2022-03-01T11:06:16.167671Z",
     "iopub.status.idle": "2022-03-01T11:06:16.238156Z",
     "shell.execute_reply": "2022-03-01T11:06:16.238781Z",
     "shell.execute_reply.started": "2022-03-01T06:15:21.046124Z"
    },
    "papermill": {
     "duration": 0.109379,
     "end_time": "2022-03-01T11:06:16.238982",
     "exception": false,
     "start_time": "2022-03-01T11:06:16.129603",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-20T12:31:21.875387Z",
     "start_time": "2023-08-20T12:31:21.835466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               image             label\ncount          18353             18353\nunique         18353               176\ntop     images/0.jpg  maclura_pomifera\nfreq               1               353",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>18353</td>\n      <td>18353</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>18353</td>\n      <td>176</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>images/0.jpg</td>\n      <td>maclura_pomifera</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>353</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "available-technical",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-03-01T11:06:16.286558Z",
     "iopub.status.busy": "2022-03-01T11:06:16.285810Z",
     "iopub.status.idle": "2022-03-01T11:06:16.293064Z",
     "shell.execute_reply": "2022-03-01T11:06:16.293698Z",
     "shell.execute_reply.started": "2022-03-01T06:40:54.863516Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.036165,
     "end_time": "2022-03-01T11:06:16.293876",
     "exception": false,
     "start_time": "2022-03-01T11:06:16.257711",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-20T12:31:21.875700Z",
     "start_time": "2023-08-20T12:31:21.844383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    },
    {
     "data": {
      "text/plain": "['abies_concolor',\n 'abies_nordmanniana',\n 'acer_campestre',\n 'acer_ginnala',\n 'acer_griseum',\n 'acer_negundo',\n 'acer_palmatum',\n 'acer_pensylvanicum',\n 'acer_platanoides',\n 'acer_pseudoplatanus']"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把label文件排个序\n",
    "# set() 函数创建一个无序不重复元素集\n",
    "# list() 创建列表\n",
    "leaves_labels = sorted(list(set(labels_dataframe['label'])))\n",
    "n_classes = len(leaves_labels)\n",
    "print(n_classes)\n",
    "leaves_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "closed-transformation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T11:06:16.342973Z",
     "iopub.status.busy": "2022-03-01T11:06:16.342138Z",
     "iopub.status.idle": "2022-03-01T11:06:16.344370Z",
     "shell.execute_reply": "2022-03-01T11:06:16.343708Z",
     "shell.execute_reply.started": "2022-03-01T06:40:58.823832Z"
    },
    "papermill": {
     "duration": 0.031056,
     "end_time": "2022-03-01T11:06:16.344519",
     "exception": false,
     "start_time": "2022-03-01T11:06:16.313463",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-20T12:31:21.875763Z",
     "start_time": "2023-08-20T12:31:21.848406Z"
    }
   },
   "outputs": [],
   "source": [
    "# 把label转成对应的数字\n",
    "class_to_num = dict(zip(leaves_labels, range(n_classes)))\n",
    "# class_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "controlled-genesis",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T11:06:16.402240Z",
     "iopub.status.busy": "2022-03-01T11:06:16.401425Z",
     "iopub.status.idle": "2022-03-01T11:06:16.403676Z",
     "shell.execute_reply": "2022-03-01T11:06:16.402957Z",
     "shell.execute_reply.started": "2022-03-01T06:41:00.247545Z"
    },
    "papermill": {
     "duration": 0.037459,
     "end_time": "2022-03-01T11:06:16.403839",
     "exception": false,
     "start_time": "2022-03-01T11:06:16.366380",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-20T12:31:21.875814Z",
     "start_time": "2023-08-20T12:31:21.850645Z"
    }
   },
   "outputs": [],
   "source": [
    "# 再转换回来，方便最后预测的时候使用\n",
    "num_to_class = {v: k for k, v in class_to_num.items()}\n",
    "# num_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "outdoor-batch",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T11:06:16.465492Z",
     "iopub.status.busy": "2022-03-01T11:06:16.464641Z",
     "iopub.status.idle": "2022-03-01T11:06:16.484200Z",
     "shell.execute_reply": "2022-03-01T11:06:16.485124Z",
     "shell.execute_reply.started": "2022-03-01T06:41:44.054114Z"
    },
    "papermill": {
     "duration": 0.0614,
     "end_time": "2022-03-01T11:06:16.485309",
     "exception": false,
     "start_time": "2022-03-01T11:06:16.423909",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-20T12:31:21.875985Z",
     "start_time": "2023-08-20T12:31:21.852380Z"
    }
   },
   "outputs": [],
   "source": [
    "# 继承pytorch的dataset，创建自己的\n",
    "class LeavesData(Dataset):\n",
    "    def __init__(self, csv_path, file_path, mode='train', valid_ratio=0.2, resize_height=256, resize_width=256):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): csv 文件路径\n",
    "            img_path (string): 图像文件所在路径\n",
    "            mode (string): 训练模式还是测试模式\n",
    "            valid_ratio (float): 验证集比例\n",
    "        \"\"\"\n",
    "\n",
    "        # 需要调整后的照片尺寸，我这里每张图片的大小尺寸不一致#\n",
    "        self.resize_height = resize_height\n",
    "        self.resize_width = resize_width\n",
    "\n",
    "        self.file_path = file_path\n",
    "        self.mode = mode\n",
    "\n",
    "        # 读取 csv 文件\n",
    "        # 利用pandas读取csv文件\n",
    "        self.data_info = pd.read_csv(csv_path, header=None)  #header=None是去掉表头部分\n",
    "        # 计算 length\n",
    "        self.data_len = len(self.data_info.index) - 1\n",
    "        self.train_len = int(self.data_len * (1 - valid_ratio))\n",
    "\n",
    "        if mode == 'train':\n",
    "            # 第一列包含图像文件的名称\n",
    "            self.train_image = np.asarray(\n",
    "                self.data_info.iloc[1:self.train_len, 0])  #self.data_info.iloc[1:,0]表示读取第一列，从第二行开始到train_len\n",
    "            # 第二列是图像的 label\n",
    "            self.train_label = np.asarray(self.data_info.iloc[1:self.train_len, 1])\n",
    "            self.image_arr = self.train_image\n",
    "            self.label_arr = self.train_label\n",
    "        elif mode == 'valid':\n",
    "            self.valid_image = np.asarray(self.data_info.iloc[self.train_len:, 0])\n",
    "            self.valid_label = np.asarray(self.data_info.iloc[self.train_len:, 1])\n",
    "            self.image_arr = self.valid_image\n",
    "            self.label_arr = self.valid_label\n",
    "        elif mode == 'test':\n",
    "            self.test_image = np.asarray(self.data_info.iloc[1:, 0])\n",
    "            self.image_arr = self.test_image\n",
    "\n",
    "        self.real_len = len(self.image_arr)\n",
    "\n",
    "        print('Finished reading the {} set of Leaves Dataset ({} samples found)'\n",
    "              .format(mode, self.real_len))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 从 image_arr中得到索引对应的文件名\n",
    "        single_image_name = self.image_arr[index]\n",
    "\n",
    "        # 读取图像文件\n",
    "        img_as_img = Image.open(self.file_path + single_image_name)\n",
    "\n",
    "        #如果需要将RGB三通道的图片转换成灰度图片可参考下面两行\n",
    "        #         if img_as_img.mode != 'L':\n",
    "        #             img_as_img = img_as_img.convert('L')\n",
    "\n",
    "        #设置好需要转换的变量，还可以包括一系列的nomarlize等等操作\n",
    "        if self.mode == 'train':\n",
    "            transform = transforms.Compose([\n",
    "                # transforms.RandomResizedCrop((224,224), scale=(0.8, 1), ratio=(0.8, 1.2)), #随机剪裁\n",
    "                # transforms.transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5), #颜色亮度色调\n",
    "                # transforms.Resize((224, 224)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),  #随机水平翻转 选择一个概率\n",
    "                transforms.RandomVerticalFlip(p=0.5),  #随机水平翻转 选择一个概率\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        else:\n",
    "            # valid和test不做数据增强\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "\n",
    "        img_as_img = transform(img_as_img)\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return img_as_img\n",
    "        else:\n",
    "            # 得到图像的 string label\n",
    "            label = self.label_arr[index]\n",
    "            # number label\n",
    "            number_label = class_to_num[label]\n",
    "\n",
    "            return img_as_img, number_label  #返回每一个index对应的图片数据和对应的label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.real_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "objective-accessory",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-03-01T11:06:16.568889Z",
     "iopub.status.busy": "2022-03-01T11:06:16.568080Z",
     "iopub.status.idle": "2022-03-01T11:06:16.639158Z",
     "shell.execute_reply": "2022-03-01T11:06:16.639760Z",
     "shell.execute_reply.started": "2022-03-01T06:41:53.847099Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.117199,
     "end_time": "2022-03-01T11:06:16.639955",
     "exception": false,
     "start_time": "2022-03-01T11:06:16.522756",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-20T12:31:21.888227Z",
     "start_time": "2023-08-20T12:31:21.859255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading the train set of Leaves Dataset (14681 samples found)\n",
      "Finished reading the valid set of Leaves Dataset (3672 samples found)\n",
      "Finished reading the test set of Leaves Dataset (8800 samples found)\n",
      "<__main__.LeavesData object at 0x154d39970>\n",
      "<__main__.LeavesData object at 0x154cb83d0>\n",
      "<__main__.LeavesData object at 0x155085df0>\n"
     ]
    }
   ],
   "source": [
    "train_path = '../data/classify-leaves/train.csv'\n",
    "test_path = '../data/classify-leaves/test.csv'\n",
    "# csv文件中已经images的路径了，因此这里只到上一级目录\n",
    "img_path = '../data/classify-leaves/'\n",
    "\n",
    "train_dataset = LeavesData(train_path, img_path, mode='train')\n",
    "val_dataset = LeavesData(train_path, img_path, mode='valid')\n",
    "test_dataset = LeavesData(test_path, img_path, mode='test')\n",
    "print(train_dataset)\n",
    "print(val_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "answering-allen",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T11:06:16.697428Z",
     "iopub.status.busy": "2022-03-01T11:06:16.696744Z",
     "iopub.status.idle": "2022-03-01T11:06:16.698432Z",
     "shell.execute_reply": "2022-03-01T11:06:16.697896Z",
     "shell.execute_reply.started": "2022-03-01T06:42:02.600151Z"
    },
    "papermill": {
     "duration": 0.033011,
     "end_time": "2022-03-01T11:06:16.698545",
     "exception": false,
     "start_time": "2022-03-01T11:06:16.665534",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-20T12:31:21.888326Z",
     "start_time": "2023-08-20T12:31:21.882089Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义data loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=5\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=5\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "divided-accordance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T11:06:16.746371Z",
     "iopub.status.busy": "2022-03-01T11:06:16.745550Z",
     "iopub.status.idle": "2022-03-01T11:06:16.792574Z",
     "shell.execute_reply": "2022-03-01T11:06:16.793636Z",
     "shell.execute_reply.started": "2022-03-01T06:42:07.803696Z"
    },
    "papermill": {
     "duration": 0.074983,
     "end_time": "2022-03-01T11:06:16.793863",
     "exception": false,
     "start_time": "2022-03-01T11:06:16.718880",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-20T12:31:21.888415Z",
     "start_time": "2023-08-20T12:31:21.884525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# 看一下是在cpu还是GPU上\n",
    "def get_device():\n",
    "    return torch.device('mps')\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "historical-seminar",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T11:06:16.847643Z",
     "iopub.status.busy": "2022-03-01T11:06:16.846875Z",
     "iopub.status.idle": "2022-03-01T11:06:16.851157Z",
     "shell.execute_reply": "2022-03-01T11:06:16.852688Z",
     "shell.execute_reply.started": "2022-03-01T06:49:37.788225Z"
    },
    "papermill": {
     "duration": 0.035727,
     "end_time": "2022-03-01T11:06:16.852857",
     "exception": false,
     "start_time": "2022-03-01T11:06:16.817130",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-20T12:31:21.895681Z",
     "start_time": "2023-08-20T12:31:21.888290Z"
    }
   },
   "outputs": [],
   "source": [
    "# 是否要冻住模型的前面一些层\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    #     if feature_extracting:\n",
    "    #         model = model\n",
    "    #         for i, param in enumerate(model.children()):\n",
    "    #             if i == 8:\n",
    "    #                 break\n",
    "    #             param.requires_grad = False\n",
    "    if feature_extracting:\n",
    "        model = model\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "# resnet34模型\n",
    "def res_model(num_classes, feature_extract=False, use_pretrained=True):\n",
    "    model_ft = models.resnet34(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    #     model_ft.fc = nn.Sequential(\n",
    "    #         nn.Linear(num_ftrs, 512),\n",
    "    #         nn.ReLU(inplace=True),\n",
    "    #         nn.Dropout(.3),\n",
    "    #         nn.Linear(512, len(num_to_class))\n",
    "    #     )\n",
    "    model_ft.fc = nn.Sequential(\n",
    "        nn.Linear(num_ftrs, num_classes)\n",
    "    )\n",
    "    return model_ft\n",
    "\n",
    "\n",
    "# resnext50模型\n",
    "def resnext_model(num_classes, feature_extract=False, use_pretrained=True):\n",
    "    model_ft = models.resnext50_32x4d(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Sequential(nn.Linear(num_ftrs, num_classes))\n",
    "\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "sunrise-omaha",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T11:06:16.901696Z",
     "iopub.status.busy": "2022-03-01T11:06:16.899880Z",
     "iopub.status.idle": "2022-03-01T11:06:16.902509Z",
     "shell.execute_reply": "2022-03-01T11:06:16.903099Z",
     "shell.execute_reply.started": "2022-03-01T06:49:48.694082Z"
    },
    "papermill": {
     "duration": 0.029481,
     "end_time": "2022-03-01T11:06:16.903293",
     "exception": false,
     "start_time": "2022-03-01T11:06:16.873812",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-20T12:31:21.895838Z",
     "start_time": "2023-08-20T12:31:21.890115Z"
    }
   },
   "outputs": [],
   "source": [
    "# 超参数\n",
    "learning_rate = 3e-4\n",
    "weight_decay = 1e-3\n",
    "num_epoch = 50\n",
    "model_path = '../data/pre-resnext-model/pre_resnext_model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frank/anaconda3/envs/d2l-zh/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/frank/anaconda3/envs/d2l-zh/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 0/918 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/frank/anaconda3/envs/d2l-zh/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/frank/anaconda3/envs/d2l-zh/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'LeavesData' on <module '__main__' (built-in)>\n",
      "  0%|          | 0/918 [03:51<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[56], line 27\u001B[0m\n\u001B[1;32m     25\u001B[0m i \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Iterate the training set by batches.\u001B[39;00m\n\u001B[0;32m---> 27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m tqdm(train_loader):\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;66;03m# A batch consists of image data and corresponding labels.\u001B[39;00m\n\u001B[1;32m     29\u001B[0m     imgs, labels \u001B[38;5;241m=\u001B[39m batch\n\u001B[1;32m     30\u001B[0m     imgs \u001B[38;5;241m=\u001B[39m imgs\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/site-packages/tqdm/std.py:1178\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1175\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1178\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1179\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1180\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1181\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/site-packages/torch/utils/data/dataloader.py:435\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    433\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[1;32m    434\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 435\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/site-packages/torch/utils/data/dataloader.py:381\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    380\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[0;32m--> 381\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1034\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[0;34m(self, loader)\u001B[0m\n\u001B[1;32m   1027\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1028\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[1;32m   1029\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[1;32m   1030\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[1;32m   1031\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[1;32m   1032\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[1;32m   1033\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[0;32m-> 1034\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[1;32m   1036\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/multiprocessing/process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[1;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    120\u001B[0m _cleanup()\n\u001B[0;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/multiprocessing/context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/multiprocessing/context.py:284\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    282\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m    283\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_posix\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[0;32m--> 284\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, process_obj):\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fds \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 32\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/multiprocessing/popen_fork.py:19\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinalizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_launch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/multiprocessing/popen_spawn_posix.py:62\u001B[0m, in \u001B[0;36mPopen._launch\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msentinel \u001B[38;5;241m=\u001B[39m parent_r\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(parent_w, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m, closefd\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m---> 62\u001B[0m         \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetbuffer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     64\u001B[0m     fds_to_close \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize a model, and put it on the device specified.\n",
    "#model = res_model(176)\n",
    "model = resnext_model(176)\n",
    "model = model.to(device)\n",
    "model.device = device\n",
    "# For the classification task, we use cross-entropy as the measurement of performance.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n",
    "# optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = learning_rate, weight_decay=weight_decay)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0, last_epoch=-1)\n",
    "\n",
    "# The number of training epochs.\n",
    "n_epochs = num_epoch\n",
    "\n",
    "best_acc = 0.0\n",
    "for epoch in range(n_epochs):\n",
    "    # ---------- Training ----------\n",
    "    # Make sure the model is in train mode before training.\n",
    "    model.train()\n",
    "    # These are used to record information in training.\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "    i = 0\n",
    "    # Iterate the training set by batches.\n",
    "    for batch in tqdm(train_loader):\n",
    "        # A batch consists of image data and corresponding labels.\n",
    "        imgs, labels = batch\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward the data. (Make sure data and model are on the same device.)\n",
    "        logits = model(imgs)\n",
    "        # Calculate the cross-entropy loss.\n",
    "        # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # Gradients stored in the parameters in the previous step should be cleared out first.\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the gradients for parameters.\n",
    "        loss.backward()\n",
    "        # Update the parameters with computed gradients.\n",
    "        optimizer.step()\n",
    "        # 更新学习率------------------------------------------------------------------------------\n",
    "        scheduler.step()\n",
    "        if (i % 500 == 0):\n",
    "            print(\"learning_rate:\", scheduler.get_last_lr()[0])\n",
    "        i = i + 1\n",
    "\n",
    "        # Compute the accuracy for current batch.\n",
    "        acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        # Record the loss and accuracy.\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "    # The average loss and accuracy of the training set is the average of the recorded values.\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "\n",
    "    # Print the information.\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "    # ---------- Validation ----------\n",
    "    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n",
    "    model.eval()\n",
    "    # These are used to record information in validation.\n",
    "    valid_loss = []\n",
    "    valid_accs = []\n",
    "\n",
    "    # Iterate the validation set by batches.\n",
    "    for batch in tqdm(val_loader):\n",
    "        imgs, labels = batch\n",
    "        # We don't need gradient in validation.\n",
    "        # Using torch.no_grad() accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "\n",
    "        # We can still compute the loss (but not the gradient).\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "\n",
    "        # Compute the accuracy for current batch.\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        # Record the loss and accuracy.\n",
    "        valid_loss.append(loss.item())\n",
    "        valid_accs.append(acc)\n",
    "\n",
    "    # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "\n",
    "    # Print the information.\n",
    "    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "\n",
    "    # if the model improves, save a checkpoint at this epoch\n",
    "    if valid_acc > best_acc:\n",
    "        best_acc = valid_acc\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print('saving model with acc {:.3f}'.format(best_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T12:35:14.007780Z",
     "start_time": "2023-08-20T12:31:21.896012Z"
    }
   },
   "id": "ac7db649b370fe4f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-sigma",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T11:06:17.006748Z",
     "iopub.status.busy": "2022-03-01T11:06:17.005921Z",
     "iopub.status.idle": "2022-03-01T11:06:17.008061Z",
     "shell.execute_reply": "2022-03-01T11:06:17.007447Z",
     "shell.execute_reply.started": "2022-03-01T06:15:21.617585Z"
    },
    "papermill": {
     "duration": 0.029139,
     "end_time": "2022-03-01T11:06:17.008196",
     "exception": false,
     "start_time": "2022-03-01T11:06:16.979057",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-08-20T12:35:14.007698Z"
    }
   },
   "outputs": [],
   "source": [
    "saveFileName = './submission/submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-isaac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T11:06:17.061218Z",
     "iopub.status.busy": "2022-03-01T11:06:17.060466Z",
     "iopub.status.idle": "2022-03-01T11:06:58.829465Z",
     "shell.execute_reply": "2022-03-01T11:06:58.830008Z",
     "shell.execute_reply.started": "2022-03-01T11:04:06.223437Z"
    },
    "papermill": {
     "duration": 41.800818,
     "end_time": "2022-03-01T11:06:58.830211",
     "exception": false,
     "start_time": "2022-03-01T11:06:17.029393",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-08-20T12:35:14.011061Z",
     "start_time": "2023-08-20T12:35:14.009773Z"
    }
   },
   "outputs": [],
   "source": [
    "## predict\n",
    "#model = res_model(176)\n",
    "model = resnext_model(176)\n",
    "\n",
    "# create model and load weights from checkpoint\n",
    "model = model.to(device)\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Make sure the model is in eval mode.\n",
    "# Some modules like Dropout or BatchNorm affect if the model is in training mode.\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store the predictions.\n",
    "predictions = []\n",
    "# Iterate the testing set by batches.\n",
    "for batch in tqdm(test_loader):\n",
    "    imgs = batch\n",
    "    with torch.no_grad():\n",
    "        logits = model(imgs.to(device))\n",
    "\n",
    "    # Take the class with greatest logit as prediction and record it.\n",
    "    predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n",
    "\n",
    "preds = []\n",
    "for i in predictions:\n",
    "    preds.append(num_to_class[i])\n",
    "\n",
    "test_data = pd.read_csv(test_path)\n",
    "test_data['label'] = pd.Series(preds)\n",
    "submission = pd.concat([test_data['image'], test_data['label']], axis=1)\n",
    "submission.to_csv(saveFileName, index=False)\n",
    "print(\"Done!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 53.678361,
   "end_time": "2022-03-01T11:07:00.966051",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-01T11:06:07.287690",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0b9aeb98210f428496c6bf5efa717c5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2927458c5d7f4594ab1b414badcc5eac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c19b2937b2a445aa2f4fa01172ebb73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59acc5c397324d8f8483fcf72021a5c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "774a720e7bfe44cea4507a9d6a028310": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_59acc5c397324d8f8483fcf72021a5c0",
       "placeholder": "​",
       "style": "IPY_MODEL_933d3cdb6fbd40dda7a51e67100265e1",
       "value": "100%"
      }
     },
     "78594a23994f42f79847689f2af953bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_774a720e7bfe44cea4507a9d6a028310",
        "IPY_MODEL_97ab53bb2566472994acc503dcab4163",
        "IPY_MODEL_b9ce82d425844117a3996c6458eccacf"
       ],
       "layout": "IPY_MODEL_2c19b2937b2a445aa2f4fa01172ebb73"
      }
     },
     "7a1dff75dc71439cb08cd3b02d0a9cb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "933d3cdb6fbd40dda7a51e67100265e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "97ab53bb2566472994acc503dcab4163": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c20c9384f8cc4cc3ab3cb11fe1a399f1",
       "max": 1.00441675E8,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7a1dff75dc71439cb08cd3b02d0a9cb7",
       "value": 1.00441675E8
      }
     },
     "b9ce82d425844117a3996c6458eccacf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2927458c5d7f4594ab1b414badcc5eac",
       "placeholder": "​",
       "style": "IPY_MODEL_0b9aeb98210f428496c6bf5efa717c5c",
       "value": " 95.8M/95.8M [00:03&lt;00:00, 32.2MB/s]"
      }
     },
     "c20c9384f8cc4cc3ab3cb11fe1a399f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
