{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0834023"
   },
   "source": [
    "# 实战Kaggle比赛：狗的品种识别（ImageNet Dogs）\n",
    "\n",
    "本节我们将在Kaggle上实战狗品种识别问题。\n",
    "本次(**比赛网址是https://www.kaggle.com/c/dog-breed-identification**)。\n",
    " :numref:`fig_kaggle_dog`显示了鉴定比赛网页上的信息。\n",
    "需要一个Kaggle账户才能提交结果。\n",
    "\n",
    "在这场比赛中，我们将识别120类不同品种的狗。\n",
    "这个数据集实际上是著名的ImageNet的数据集子集。与 :numref:`sec_kaggle_cifar10`中CIFAR-10数据集中的图像不同，\n",
    "ImageNet数据集中的图像更高更宽，且尺寸不一。\n",
    "\n",
    "![狗的品种鉴定比赛网站，可以通过单击“数据”选项卡来获得比赛数据集。](../img/kaggle-dog.jpg)\n",
    ":width:`400px`\n",
    ":label:`fig_kaggle_dog`\n"
   ],
   "id": "c0834023"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6107,
     "status": "ok",
     "timestamp": 1698996638015,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     },
     "user_tz": -480
    },
    "id": "z04fvtxhlr_e",
    "outputId": "066817d5-162c-4d38-f9c5-35343ca84e51"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.flush_and_unmount()\n",
    "# drive.mount('/content/drive', force_remount=False)\n"
   ],
   "id": "z04fvtxhlr_e"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "Mx8a-EiKlwpz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996638015,
     "user_tz": -480,
     "elapsed": 8,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    }
   },
   "outputs": [],
   "source": [
    "# !unzip '/content/drive/MyDrive/Colab Notebooks/dog-breed-identification.zip' -d '/content/drive/MyDrive/data/dog-breed-identification'\n"
   ],
   "id": "Mx8a-EiKlwpz"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1698996638015,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     },
     "user_tz": -480
    },
    "id": "xi6jHPhP159R",
    "outputId": "8c9b1441-119d-4a26-d30c-35a19b4589f0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fri Nov  3 07:30:37 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   33C    P0    38W / 300W |   3148MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# !nvidia-smi"
   ],
   "id": "xi6jHPhP159R"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "5kDIzX2xYMhp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996638015,
     "user_tz": -480,
     "elapsed": 5,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    }
   },
   "outputs": [],
   "source": [
    "# !pip install d2l==0.17.6"
   ],
   "id": "5kDIzX2xYMhp"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4d01d08b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996638015,
     "user_tz": -480,
     "elapsed": 5,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-11-03T07:33:40.028790Z",
     "start_time": "2023-11-03T07:33:37.914066Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ],
   "id": "4d01d08b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1698996638015,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     },
     "user_tz": -480
    },
    "id": "mAoVUv4IKspb",
    "outputId": "21b5c817-b739-475a-e36a-7f31e2e76da7",
    "ExecuteTime": {
     "end_time": "2023-11-03T07:33:46.607838Z",
     "start_time": "2023-11-03T07:33:46.475065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/frank/Desktop/d2l-zh/pytorch/chapter_computer-vision\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ],
   "id": "mAoVUv4IKspb"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6c7cb76"
   },
   "source": [
    "## 获取和整理数据集\n",
    "\n",
    "比赛数据集分为训练集和测试集，分别包含RGB（彩色）通道的10222张、10357张JPEG图像。\n",
    "在训练数据集中，有120种犬类，如拉布拉多、贵宾、腊肠、萨摩耶、哈士奇、吉娃娃和约克夏等。\n",
    "\n",
    "### 下载数据集\n",
    "\n",
    "登录Kaggle后，可以点击 :numref:`fig_kaggle_dog`中显示的竞争网页上的“数据”选项卡，然后点击“全部下载”按钮下载数据集。在`../data`中解压下载的文件后，将在以下路径中找到整个数据集：\n",
    "\n",
    "* ../data/dog-breed-identification/labels.csv\n",
    "* ../data/dog-breed-identification/sample_submission.csv\n",
    "* ../data/dog-breed-identification/train\n",
    "* ../data/dog-breed-identification/test\n",
    "\n",
    "\n",
    "上述结构与 :numref:`sec_kaggle_cifar10`的CIFAR-10类似，其中文件夹`train/`和`test/`分别包含训练和测试狗图像，`labels.csv`包含训练图像的标签。\n",
    "\n",
    "同样，为了便于入门，[**我们提供完整数据集的小规模样本**]：`train_valid_test_tiny.zip`。\n",
    "如果要在Kaggle比赛中使用完整的数据集，则需要将下面的`demo`变量更改为`False`。\n"
   ],
   "id": "f6c7cb76"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8530da04",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996638015,
     "user_tz": -480,
     "elapsed": 3,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-11-03T07:33:50.471416Z",
     "start_time": "2023-11-03T07:33:50.460793Z"
    }
   },
   "outputs": [],
   "source": [
    "d2l.DATA_HUB['dog_tiny'] = (d2l.DATA_URL + 'kaggle_dog_tiny.zip',\n",
    "                            '0cb91d09b814ecdc07b50f31f8dcad3e81d6a86d')\n",
    "\n",
    "# 如果使用Kaggle比赛的完整数据集，请将下面的变量更改为False\n",
    "demo = False\n",
    "if demo:\n",
    "    data_dir = d2l.download_extract('dog_tiny')\n",
    "else:\n",
    "    data_dir = os.path.join('..', 'data', 'dog-breed-identification')"
   ],
   "id": "8530da04"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e79f9215"
   },
   "source": [
    "### [**整理数据集**]\n",
    "\n",
    "我们可以像 :numref:`sec_kaggle_cifar10`中所做的那样整理数据集，即从原始训练集中拆分验证集，然后将图像移动到按标签分组的子文件夹中。\n",
    "\n",
    "下面的`reorg_dog_data`函数读取训练数据标签、拆分验证集并整理训练集。\n"
   ],
   "id": "e79f9215"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "97daf7df",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996638015,
     "user_tz": -480,
     "elapsed": 3,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-11-03T07:33:53.869028Z",
     "start_time": "2023-11-03T07:33:53.847723Z"
    }
   },
   "outputs": [],
   "source": [
    "def reorg_dog_data(data_dir, valid_ratio):\n",
    "    labels = d2l.read_csv_labels(os.path.join(data_dir, 'labels.csv'))\n",
    "    d2l.reorg_train_valid(data_dir, labels, valid_ratio)\n",
    "    d2l.reorg_test(data_dir)\n",
    "\n",
    "\n",
    "batch_size = 32 if demo else 128\n",
    "valid_ratio = 0.1\n",
    "# reorg_dog_data(data_dir, valid_ratio)\n",
    "# len(data_dir), data_dir[0]"
   ],
   "id": "97daf7df"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b665aa35"
   },
   "source": [
    "## [**图像增广**]\n",
    "\n",
    "回想一下，这个狗品种数据集是ImageNet数据集的子集，其图像大于 :numref:`sec_kaggle_cifar10`中CIFAR-10数据集的图像。\n",
    "下面我们看一下如何在相对较大的图像上使用图像增广。\n"
   ],
   "id": "b665aa35"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "d109db32",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996638015,
     "user_tz": -480,
     "elapsed": 3,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-11-03T07:33:56.480577Z",
     "start_time": "2023-11-03T07:33:56.460273Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_train = torchvision.transforms.Compose([\n",
    "    # 随机裁剪图像，所得图像为原始面积的0.08～1之间，高宽比在3/4和4/3之间。\n",
    "    # 然后，缩放图像以创建224x224的新图像\n",
    "    torchvision.transforms.RandomResizedCrop(224, scale=(0.08, 1.0),\n",
    "                                             ratio=(3.0 / 4.0, 4.0 / 3.0)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(degrees=15),\n",
    "    # 随机更改亮度，对比度和饱和度\n",
    "    torchvision.transforms.ColorJitter(brightness=0.4,\n",
    "                                       contrast=0.4,\n",
    "                                       saturation=0.4),\n",
    "    # 添加随机噪声\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    # 标准化图像的每个通道\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])])"
   ],
   "id": "d109db32"
  },
  {
   "cell_type": "code",
   "source": [
    "# transform_train_swin = torchvision.transforms.Compose([\n",
    "#     # 随机裁剪图像，所得图像为原始面积的0.08～1之间，高宽比在3/4和4/3之间。\n",
    "#     # 然后，缩放图像以创建224x224的新图像\n",
    "#     torchvision.transforms.RandomResizedCrop(256, scale=(0.08, 1.0),\n",
    "#                                              ratio=(3.0 / 4.0, 4.0 / 3.0)),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(),\n",
    "#     torchvision.transforms.RandomRotation(degrees=15),\n",
    "#     # 随机更改亮度，对比度和饱和度\n",
    "#     torchvision.transforms.ColorJitter(brightness=0.4,\n",
    "#                                        contrast=0.4,\n",
    "#                                        saturation=0.4),\n",
    "#     # 添加随机噪声\n",
    "#     torchvision.transforms.ToTensor(),\n",
    "#     # 标准化图像的每个通道\n",
    "#     torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "#                                      [0.229, 0.224, 0.225])])"
   ],
   "metadata": {
    "id": "gBAfS2wd43m-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996638016,
     "user_tz": -480,
     "elapsed": 4,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    }
   },
   "id": "gBAfS2wd43m-",
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff29a039"
   },
   "source": [
    "测试时，我们只使用确定性的图像预处理操作。\n"
   ],
   "id": "ff29a039"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3bdc1caa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996638016,
     "user_tz": -480,
     "elapsed": 4,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-11-03T07:34:01.701357Z",
     "start_time": "2023-11-03T07:34:01.687962Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_test = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    # 从图像中心裁切224x224大小的图片\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])])"
   ],
   "id": "3bdc1caa"
  },
  {
   "cell_type": "code",
   "source": [
    "# transform_test_swin = torchvision.transforms.Compose([\n",
    "#     torchvision.transforms.Resize(280),\n",
    "#     # 从图像中心裁切224x224大小的图片\n",
    "#     torchvision.transforms.CenterCrop(256),\n",
    "#     torchvision.transforms.ToTensor(),\n",
    "#     torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "#                                      [0.229, 0.224, 0.225])])"
   ],
   "metadata": {
    "id": "8sIlHw3r477g",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996638016,
     "user_tz": -480,
     "elapsed": 4,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    }
   },
   "id": "8sIlHw3r477g",
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58f4c8c8"
   },
   "source": [
    "## [**读取数据集**]\n",
    "\n",
    "与 :numref:`sec_kaggle_cifar10`一样，我们可以读取整理后的含原始图像文件的数据集。\n"
   ],
   "id": "58f4c8c8"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ab4f4531",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996643795,
     "user_tz": -480,
     "elapsed": 5783,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-11-03T07:34:04.231463Z",
     "start_time": "2023-11-03T07:34:04.081071Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds, train_valid_ds = [torchvision.datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'train_valid_test', folder),\n",
    "    transform=transform_train) for folder in ['train', 'train_valid']]\n",
    "\n",
    "valid_ds, test_ds = [torchvision.datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'train_valid_test', folder),\n",
    "    transform=transform_test) for folder in ['valid', 'test']]"
   ],
   "id": "ab4f4531"
  },
  {
   "cell_type": "code",
   "source": [
    "# train_ds_swin, train_valid_ds_swin = [torchvision.datasets.ImageFolder(\n",
    "#     os.path.join(data_dir, 'train_valid_test', folder),\n",
    "#     transform=transform_train_swin) for folder in ['train', 'train_valid']]\n",
    "\n",
    "# valid_ds_swin, test_ds_swin = [torchvision.datasets.ImageFolder(\n",
    "#     os.path.join(data_dir, 'train_valid_test', folder),\n",
    "#     transform=transform_test_swin) for folder in ['valid', 'test']]"
   ],
   "metadata": {
    "id": "X02q7iOg5G-d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996643795,
     "user_tz": -480,
     "elapsed": 10,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    }
   },
   "id": "X02q7iOg5G-d",
   "execution_count": 65,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1698996643795,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     },
     "user_tz": -480
    },
    "id": "LwoKDkEBRKs3",
    "outputId": "b8bda0c9-6189-48c4-ca6d-628ea8617172",
    "ExecuteTime": {
     "end_time": "2023-11-03T07:34:06.510613Z",
     "start_time": "2023-11-03T07:34:06.491719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(9502, 10222, 10357)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(train_valid_ds),len(test_ds)"
   ],
   "id": "LwoKDkEBRKs3"
  },
  {
   "cell_type": "code",
   "source": [
    "# len(train_ds_swin), len(train_valid_ds_swin),len(test_ds_swin)"
   ],
   "metadata": {
    "id": "g5EbSon55PnZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996643795,
     "user_tz": -480,
     "elapsed": 9,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    }
   },
   "id": "g5EbSon55PnZ",
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b12526f2"
   },
   "source": [
    "下面我们创建数据加载器实例的方式与 :numref:`sec_kaggle_cifar10`相同。\n"
   ],
   "id": "b12526f2"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fcc78330",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996643795,
     "user_tz": -480,
     "elapsed": 9,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-11-03T07:34:10.425963Z",
     "start_time": "2023-11-03T07:34:10.410763Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iter, train_valid_iter = [torch.utils.data.DataLoader(\n",
    "    dataset, batch_size, shuffle=True, drop_last=True)\n",
    "    for dataset in (train_ds, train_valid_ds)]\n",
    "\n",
    "valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,\n",
    "                                         drop_last=True)\n",
    "\n",
    "test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,\n",
    "                                        drop_last=False)"
   ],
   "id": "fcc78330"
  },
  {
   "cell_type": "code",
   "source": [
    "# train_iter_swin, train_valid_iter_swin = [torch.utils.data.DataLoader(\n",
    "#     dataset, batch_size, shuffle=True, drop_last=True)\n",
    "#     for dataset in (train_ds_swin, train_valid_ds_swin)]\n",
    "\n",
    "# valid_iter_swin = torch.utils.data.DataLoader(valid_ds_swin, batch_size, shuffle=False,\n",
    "#                                          drop_last=True)\n",
    "\n",
    "# test_iter_swin = torch.utils.data.DataLoader(test_ds_swin, batch_size, shuffle=False,\n",
    "#                                         drop_last=False)"
   ],
   "metadata": {
    "id": "vTXBnUbB5SsU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996643795,
     "user_tz": -480,
     "elapsed": 9,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    }
   },
   "id": "vTXBnUbB5SsU",
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abae5882"
   },
   "source": [
    "## [**微调预训练模型**]\n",
    "\n",
    "同样，本次比赛的数据集是ImageNet数据集的子集。\n",
    "因此，我们可以使用 :numref:`sec_fine_tuning`中讨论的方法在完整ImageNet数据集上选择预训练的模型，然后使用该模型提取图像特征，以便将其输入到定制的小规模输出网络中。\n",
    "深度学习框架的高级API提供了在ImageNet数据集上预训练的各种模型。\n",
    "在这里，我们选择预训练的ResNet-34模型，我们只需重复使用此模型的输出层（即提取的特征）的输入。\n",
    "然后，我们可以用一个可以训练的小型自定义输出网络替换原始输出层，例如堆叠两个完全连接的图层。\n",
    "与 :numref:`sec_fine_tuning`中的实验不同，以下内容不重新训练用于特征提取的预训练模型，这节省了梯度下降的时间和内存空间。\n",
    "\n",
    "回想一下，我们使用三个RGB通道的均值和标准差来对完整的ImageNet数据集进行图像标准化。\n",
    "事实上，这也符合ImageNet上预训练模型的标准化操作。\n"
   ],
   "id": "abae5882"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "a0d5f683",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996643795,
     "user_tz": -480,
     "elapsed": 9,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-11-03T07:34:18.880274Z",
     "start_time": "2023-11-03T07:34:18.871994Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_net(devices):\n",
    "    finetune_net = nn.Sequential()\n",
    "    finetune_net.features = torchvision.models.resnet152(pretrained=True)\n",
    "    # 定义一个新的输出网络，共有120个输出类别\n",
    "    finetune_net.output_new = nn.Sequential(nn.Linear(1000, 256),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(256, 120))\n",
    "    # 将模型参数分配给用于计算的CPU或GPU\n",
    "    finetune_net = finetune_net.to(devices[0])\n",
    "    # 冻结参数\n",
    "    for param in finetune_net.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    return finetune_net\n",
    "\n",
    "from torchvision.models import ResNet152_Weights, ViT_B_16_Weights, ViT_L_32_Weights,Swin_V2_B_Weights\n",
    "\n",
    "def get_vit(devices):\n",
    "    finetune_net = nn.Sequential()\n",
    "    finetune_net.features = torchvision.models.vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # 将模型参数分配给用于计算的CPU或GPU\n",
    "    finetune_net = finetune_net.to(devices[0])\n",
    "    # 冻结参数\n",
    "    for param in finetune_net.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    finetune_net[0].heads = nn.Sequential(nn.Linear(768, 256),\n",
    "                                          nn.ReLU(), nn.Dropout(0.5),\n",
    "                                          nn.Linear(256, 120))\n",
    "    return finetune_net\n",
    "\n",
    "\n",
    "def get_vitl(devices):\n",
    "    finetune_net = nn.Sequential()\n",
    "    finetune_net.features = torchvision.models.vit_l_32(weights=ViT_L_32_Weights.IMAGENET1K_V1)\n",
    "    finetune_net.features.heads = nn.Sequential(nn.Linear(1024, 2048),\n",
    "                                          nn.ReLU(), nn.Dropout(0.5),\n",
    "                                          nn.Linear(2048, 1024),\n",
    "                                          nn.ReLU(), nn.Dropout(0.5),\n",
    "                                          nn.Linear(1024, 1024),\n",
    "                                          nn.ReLU(), nn.Dropout(0.5),\n",
    "                                          nn.Linear(1024, 1024),\n",
    "                                          nn.ReLU(), nn.Dropout(0.5),\n",
    "                                          nn.Linear(1024, 1024),\n",
    "                                          nn.ReLU(), nn.Dropout(0.5),\n",
    "                                          nn.Linear(1024, 1024),\n",
    "                                          nn.ReLU(), nn.Dropout(0.5),\n",
    "                                          nn.Linear(1024, 1024),\n",
    "                                          nn.ReLU(), nn.Dropout(0.5),\n",
    "                                          nn.Linear(1024, 256),\n",
    "                                          nn.ReLU(), nn.Dropout(0.5),\n",
    "                                          nn.Linear(256, 120))\n",
    "    # 将模型参数分配给用于计算的CPU或GPU\n",
    "    finetune_net = finetune_net.to(devices[0])\n",
    "    # 冻结参数\n",
    "    for param in finetune_net.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in finetune_net.features.heads.parameters():\n",
    "        param.requires_grad = True\n",
    "    return finetune_net\n",
    "\n",
    "def get_swin_B(devices):\n",
    "    finetune_net = nn.Sequential()\n",
    "    finetune_net.features = torchvision.models.swin_v2_b(weights=Swin_V2_B_Weights.IMAGENET1K_V1)\n",
    "    finetune_net.features.head = nn.Sequential(nn.Linear(1024, 256),\n",
    "                                          nn.ReLU(), nn.Dropout(0.5),\n",
    "                                          nn.Linear(256, 120))\n",
    "    # finetune_net.features.new_out = nn.Sequential(nn.Linear(1024, 256),\n",
    "    #                                       nn.ReLU(), nn.Dropout(0.5),\n",
    "    #                                       nn.Linear(256, 120))\n",
    "    # 将模型参数分配给用于计算的CPU或GPU\n",
    "    finetune_net = finetune_net.to(devices[0])\n",
    "    # 冻结参数\n",
    "    for param in finetune_net.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in finetune_net.features.head.parameters():\n",
    "        param.requires_grad = True\n",
    "    return finetune_net\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, patch_size, channels, hidden_dim, num_heads, num_layers, num_classes):\n",
    "        super(VisionTransformer, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.embedding = nn.Linear(patch_size * patch_size * channels, hidden_dim)\n",
    "        self.positional_embedding = nn.Parameter(\n",
    "            torch.randn(1, (224 // patch_size) * (224 // patch_size) + 1, hidden_dim))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=256,\n",
    "            nhead=8,\n",
    "            dim_feedforward=1024,\n",
    "            dropout=0.1,\n",
    "            activation=nn.functional.relu,\n",
    "            layer_norm_eps=1e-5,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        # self.test = nn.Transformer()\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, hidden_dim))\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract patches\n",
    "        patches = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)\n",
    "        patches = patches.contiguous().view(x.shape[0], -1, self.patch_size * self.patch_size * x.shape[1])\n",
    "\n",
    "        # Embed patches\n",
    "        x = self.embedding(patches)\n",
    "\n",
    "        # Add positional embedding\n",
    "        x = x + self.positional_embedding[:, :-1]\n",
    "        cls_tokens = self.cls_token.repeat(x.shape[0], 1, 1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.positional_embedding\n",
    "\n",
    "        # Pass through transformer\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # Classifier on the CLS token\n",
    "        x = self.fc(x[:, 0])\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_myvit():\n",
    "    net = VisionTransformer(16, 3, 512, 8, 4, 120)\n",
    "    return net\n",
    "\n",
    "class VisionTransformer_conv(nn.Module):\n",
    "    def __init__(self, img_size, patch_size, channels, hidden_dim, num_heads,dim_feedforward, num_layers, num_classes):\n",
    "        super(VisionTransformer_conv, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = (img_size // patch_size) * (img_size // patch_size)\n",
    "\n",
    "        # 使用卷积层代替线性层以直接从图像中提取patch\n",
    "        self.patch_embed = nn.Conv2d(channels, hidden_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "        self.positional_embedding = nn.Parameter(torch.randn(1, self.num_patches + 1, hidden_dim))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=0.1,\n",
    "            activation=nn.functional.relu,\n",
    "            layer_norm_eps=1e-5,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, hidden_dim))\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 使用卷积层提取patch并展平\n",
    "        x = self.patch_embed(x)  # [B, C, H, W] -> [B, hidden_dim, H/P, W/P]\n",
    "        x = x.flatten(2)  # [B, hidden_dim, H/P * W/P]\n",
    "        x = x.transpose(1, 2)  # [B, H/P * W/P, hidden_dim]\n",
    "\n",
    "        # Add positional embedding\n",
    "        cls_tokens = self.cls_token.repeat(x.shape[0], 1, 1)  # [B, 1, hidden_dim]\n",
    "        x = torch.cat((cls_tokens, x), dim=1)  # [B, 1 + H/P * W/P, hidden_dim]\n",
    "        x = x + self.positional_embedding  # [B, 1 + H/P * W/P, hidden_dim]\n",
    "\n",
    "        # Pass through transformer\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # Classifier on the CLS token\n",
    "        x = self.fc(x[:, 0])\n",
    "        return x\n",
    "\n",
    "def get_vit_conv():\n",
    "    net = VisionTransformer_conv(224,16, 3, 256, 4, 512,1, 120)\n",
    "    return net"
   ],
   "id": "a0d5f683"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab327251"
   },
   "source": [
    "在[**计算损失**]之前，我们首先获取预训练模型的输出层的输入，即提取的特征。\n",
    "然后我们使用此特征作为我们小型自定义输出网络的输入来计算损失。\n"
   ],
   "id": "ab327251"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9cc9cdc0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996643795,
     "user_tz": -480,
     "elapsed": 9,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-11-03T07:34:21.786959Z",
     "start_time": "2023-11-03T07:34:21.769436Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "\n",
    "def evaluate_loss(data_iter, net, devices):\n",
    "    l_sum, n = 0.0, 0\n",
    "    for features, labels in data_iter:\n",
    "        features, labels = features.to(devices[0]), labels.to(devices[0])\n",
    "        outputs = net(features)\n",
    "        l = loss(outputs, labels)\n",
    "        l_sum += l.sum()\n",
    "        n += labels.numel()\n",
    "    return (l_sum / n).to('cpu')"
   ],
   "id": "9cc9cdc0"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mIlcZ3fCqS9R",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996643795,
     "user_tz": -480,
     "elapsed": 9,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-11-03T07:34:22.936547Z",
     "start_time": "2023-11-03T07:34:22.923054Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ],
   "id": "mIlcZ3fCqS9R"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "110159c7"
   },
   "source": [
    "## 定义[**训练函数**]\n",
    "\n",
    "我们将根据模型在验证集上的表现选择模型并调整超参数。\n",
    "模型训练函数`train`只迭代小型自定义输出网络的参数。\n"
   ],
   "id": "110159c7"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5678b941",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996643795,
     "user_tz": -480,
     "elapsed": 9,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-11-03T07:34:26.496587Z",
     "start_time": "2023-11-03T07:34:26.487326Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,\n",
    "          lr_decay):\n",
    "    # 只训练小型自定义输出网络\n",
    "    # net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    net = net.to(devices[0])\n",
    "    trainer = torch.optim.SGD((param for param in net.parameters()\n",
    "                               if param.requires_grad), lr=lr,\n",
    "                              momentum=0.9, weight_decay=wd)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_period, lr_decay)\n",
    "    num_batches, timer = len(train_iter), d2l.Timer()\n",
    "    legend = ['train loss']\n",
    "    if valid_iter is not None:\n",
    "        legend.append('valid loss')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = d2l.Accumulator(2)\n",
    "        for features, labels in tqdm(train_iter):\n",
    "            timer.start()\n",
    "            features, labels = features.to(devices[0]), labels.to(devices[0])\n",
    "            trainer.zero_grad()\n",
    "            output = net(features)\n",
    "            l = loss(output, labels).sum()\n",
    "            # l.requires_grad = True\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            metric.add(l, labels.shape[0])\n",
    "            timer.stop()\n",
    "        measures = f'{epoch}/{num_epochs} train loss {metric[0] / metric[1]:.3f}'\n",
    "        if valid_iter is not None:\n",
    "            valid_loss = evaluate_loss(valid_iter, net, devices)\n",
    "            measures += f', valid loss {valid_loss:.3f}'\n",
    "        scheduler.step()\n",
    "        print(measures+f',{output.shape}')\n",
    "    torch.save(net.state_dict(), '/content/drive/MyDrive/models/dog_classifier.ckpt')\n",
    "    if valid_iter is not None:\n",
    "        measures += f', valid loss {valid_loss:.3f}'\n",
    "    print(measures + f'\\n{metric[1] * num_epochs / timer.sum():.1f}'\n",
    "                     f' examples/sec on {str(devices)}')"
   ],
   "id": "5678b941"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09725612"
   },
   "source": [
    "## [**训练和验证模型**]\n",
    "\n",
    "现在我们可以训练和验证模型了，以下超参数都是可调的。\n",
    "例如，我们可以增加迭代轮数。\n",
    "另外，由于`lr_period`和`lr_decay`分别设置为2和0.9，\n",
    "因此优化算法的学习速率将在每2个迭代后乘以0.9。\n"
   ],
   "id": "09725612"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5bcd4b0a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996644285,
     "user_tz": -480,
     "elapsed": 499,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-11-03T07:35:11.005871Z",
     "start_time": "2023-11-03T07:35:10.388738Z"
    }
   },
   "outputs": [],
   "source": [
    "devices, num_epochs, lr, wd = [torch.device('mps')], 100, 1e-4, 1e-4\n",
    "lr_period, lr_decay,  = 2, 0.9\n",
    "net1=get_vit(devices)\n",
    "# net2 =  get_vitl(devices)\n",
    "# net3 =  get_swin_B(devices)\n",
    "net4 = get_vit_conv()\n",
    "# net4  "
   ],
   "id": "5bcd4b0a"
  },
  {
   "cell_type": "code",
   "source": [
    "# for name, param in net3.named_parameters():\n",
    "#     print(f\"{name} requires_grad={param.requires_grad}\")\n",
    "torch.__version__"
   ],
   "metadata": {
    "id": "6vXRxsLa6IR-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698996644285,
     "user_tz": -480,
     "elapsed": 7,
     "user": {
      "displayName": "Lingfeng Ren",
      "userId": "17783286971809197165"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "5aeeac23-094f-4ce6-e5de-41e9fe8102d7",
    "ExecuteTime": {
     "end_time": "2023-11-03T07:35:12.685150Z",
     "start_time": "2023-11-03T07:35:12.671048Z"
    }
   },
   "id": "6vXRxsLa6IR-",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.1.0'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PAZlDq2bSDkN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b9c33879-7e13-45dd-b8b4-4a23603afc57",
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-03T07:35:14.196947Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [01:32<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/100 train loss 4.243, valid loss 3.199,torch.Size([128, 120])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100 train loss 2.142, valid loss 0.931,torch.Size([128, 120])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 60/74 [01:13<00:16,  1.21s/it]"
     ]
    }
   ],
   "source": [
    "train(net1, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,\n",
    "      lr_decay)"
   ],
   "id": "PAZlDq2bSDkN"
  },
  {
   "cell_type": "code",
   "source": [
    "# train(net3, train_iter_swin, valid_iter_swin, num_epochs, lr, wd, devices, lr_period,\n",
    "#       lr_decay)"
   ],
   "metadata": {
    "id": "ZIGVmWYL5gic"
   },
   "id": "ZIGVmWYL5gic",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# train(net3, train_valid_iter_swin, None, 10, lr, wd, devices, lr_period,\n",
    "#       lr_decay)"
   ],
   "metadata": {
    "id": "fYAEa0RkAeFb"
   },
   "id": "fYAEa0RkAeFb",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# train(net2, train_valid_iter, None, 50, lr, wd, devices, lr_period,\n",
    "#       lr_decay)"
   ],
   "metadata": {
    "id": "oLVCKSuoH-TE"
   },
   "id": "oLVCKSuoH-TE",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53452ac9"
   },
   "source": [
    "## [**对测试集分类**]并在Kaggle提交结果\n",
    "\n",
    "与 :numref:`sec_kaggle_cifar10`中的最后一步类似，最终所有标记的数据（包括验证集）都用于训练模型和对测试集进行分类。\n",
    "我们将使用训练好的自定义输出网络进行分类。\n"
   ],
   "id": "53452ac9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "933ae1ca"
   },
   "outputs": [],
   "source": [
    "# net2 = get_vitl(devices)\n",
    "\n",
    "\n",
    "preds = []\n",
    "for data, label in test_iter:\n",
    "    output = torch.nn.functional.softmax(net4(data.to(devices[0])), dim=1)\n",
    "    preds.extend(output.cpu().detach().numpy())\n",
    "ids = sorted(os.listdir(\n",
    "    os.path.join(data_dir, 'train_valid_test', 'test', 'unknown')))\n",
    "with open('/content/drive/MyDrive/data/dog-breed-identification/submission.csv', 'w') as f:\n",
    "    f.write('id,' + ','.join(train_valid_ds.classes) + '\\n')\n",
    "    for i, output in zip(ids, preds):\n",
    "        f.write(i.split('.')[0] + ',' + ','.join(\n",
    "            [str(num) for num in output]) + '\\n')"
   ],
   "id": "933ae1ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fe3CflVeBPF9"
   },
   "outputs": [],
   "source": [
    "# print(net2)"
   ],
   "id": "fe3CflVeBPF9"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32f69a07"
   },
   "source": [
    "上面的代码将生成一个`submission.csv`文件，以 :numref:`sec_kaggle_house`中描述的方式提在Kaggle上提交。\n",
    "\n",
    "## 小结\n",
    "\n",
    "* ImageNet数据集中的图像比CIFAR-10图像尺寸大，我们可能会修改不同数据集上任务的图像增广操作。\n",
    "* 要对ImageNet数据集的子集进行分类，我们可以利用完整ImageNet数据集上的预训练模型来提取特征并仅训练小型自定义输出网络，这将减少计算时间和节省内存空间。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 试试使用完整Kaggle比赛数据集，增加`batch_size`（批量大小）和`num_epochs`（迭代轮数），或者设计其它超参数为`lr = 0.01`，`lr_period = 10`，和`lr_decay = 0.1`时，能取得什么结果？\n",
    "1. 如果使用更深的预训练模型，会得到更好的结果吗？如何调整超参数？能进一步改善结果吗？\n"
   ],
   "id": "32f69a07"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ac4d2a2b"
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/2833)\n"
   ],
   "id": "ac4d2a2b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f50db1dfd294b5c2"
   },
   "outputs": [],
   "source": [],
   "id": "f50db1dfd294b5c2"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "gpuType": "V100"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
