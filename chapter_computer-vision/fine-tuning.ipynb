{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f265b812",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 微调\n",
    ":label:`sec_fine_tuning`\n",
    "\n",
    "前面的一些章节介绍了如何在只有6万张图像的Fashion-MNIST训练数据集上训练模型。\n",
    "我们还描述了学术界当下使用最广泛的大规模图像数据集ImageNet，它有超过1000万的图像和1000类的物体。\n",
    "然而，我们平常接触到的数据集的规模通常在这两者之间。\n",
    "\n",
    "假如我们想识别图片中不同类型的椅子，然后向用户推荐购买链接。\n",
    "一种可能的方法是首先识别100把普通椅子，为每把椅子拍摄1000张不同角度的图像，然后在收集的图像数据集上训练一个分类模型。\n",
    "尽管这个椅子数据集可能大于Fashion-MNIST数据集，但实例数量仍然不到ImageNet中的十分之一。\n",
    "适合ImageNet的复杂模型可能会在这个椅子数据集上过拟合。\n",
    "此外，由于训练样本数量有限，训练模型的准确性可能无法满足实际要求。\n",
    "\n",
    "为了解决上述问题，一个显而易见的解决方案是收集更多的数据。\n",
    "但是，收集和标记数据可能需要大量的时间和金钱。\n",
    "例如，为了收集ImageNet数据集，研究人员花费了数百万美元的研究资金。\n",
    "尽管目前的数据收集成本已大幅降低，但这一成本仍不能忽视。\n",
    "\n",
    "另一种解决方案是应用*迁移学习*（transfer learning）将从*源数据集*学到的知识迁移到*目标数据集*。\n",
    "例如，尽管ImageNet数据集中的大多数图像与椅子无关，但在此数据集上训练的模型可能会提取更通用的图像特征，这有助于识别边缘、纹理、形状和对象组合。\n",
    "这些类似的特征也可能有效地识别椅子。\n",
    "\n",
    "## 步骤\n",
    "\n",
    "本节将介绍迁移学习中的常见技巧:*微调*（fine-tuning）。如 :numref:`fig_finetune`所示，微调包括以下四个步骤。\n",
    "\n",
    "1. 在源数据集（例如ImageNet数据集）上预训练神经网络模型，即*源模型*。\n",
    "1. 创建一个新的神经网络模型，即*目标模型*。这将复制源模型上的所有模型设计及其参数（输出层除外）。我们假定这些模型参数包含从源数据集中学到的知识，这些知识也将适用于目标数据集。我们还假设源模型的输出层与源数据集的标签密切相关；因此不在目标模型中使用该层。\n",
    "1. 向目标模型添加输出层，其输出数是目标数据集中的类别数。然后随机初始化该层的模型参数。\n",
    "1. 在目标数据集（如椅子数据集）上训练目标模型。输出层将从头开始进行训练，而所有其他层的参数将根据源模型的参数进行微调。\n",
    "\n",
    "![微调。](../img/finetune.svg)\n",
    ":label:`fig_finetune`\n",
    "\n",
    "当目标数据集比源数据集小得多时，微调有助于提高模型的泛化能力。\n",
    "\n",
    "## 热狗识别\n",
    "\n",
    "让我们通过具体案例演示微调：热狗识别。\n",
    "我们将在一个小型数据集上微调ResNet模型。该模型已在ImageNet数据集上进行了预训练。\n",
    "这个小型数据集包含数千张包含热狗和不包含热狗的图像，我们将使用微调模型来识别图像中是否包含热狗。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ff22d3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:45.116938Z",
     "iopub.status.busy": "2022-12-07T16:37:45.116615Z",
     "iopub.status.idle": "2022-12-07T16:37:49.241932Z",
     "shell.execute_reply": "2022-12-07T16:37:49.241077Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-08-20T15:04:41.593700Z",
     "start_time": "2023-08-20T15:04:41.027513Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d138ea1",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "### 获取数据集\n",
    "\n",
    "我们使用的[**热狗数据集来源于网络**]。\n",
    "该数据集包含1400张热狗的“正类”图像，以及包含尽可能多的其他食物的“负类”图像。\n",
    "含着两个类别的1000张图片用于训练，其余的则用于测试。\n",
    "\n",
    "解压下载的数据集，我们获得了两个文件夹`hotdog/train`和`hotdog/test`。\n",
    "这两个文件夹都有`hotdog`（有热狗）和`not-hotdog`（无热狗）两个子文件夹，\n",
    "子文件夹内都包含相应类的图像。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e960c12b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:49.246023Z",
     "iopub.status.busy": "2022-12-07T16:37:49.245639Z",
     "iopub.status.idle": "2022-12-07T16:37:57.315163Z",
     "shell.execute_reply": "2022-12-07T16:37:57.314243Z"
    },
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-08-20T15:04:54.955015Z",
     "start_time": "2023-08-20T15:04:41.594257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../data/hotdog.zip from http://d2l-data.s3-accelerate.amazonaws.com/hotdog.zip...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#@save\u001B[39;00m\n\u001B[1;32m      2\u001B[0m d2l\u001B[38;5;241m.\u001B[39mDATA_HUB[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhotdog\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m (d2l\u001B[38;5;241m.\u001B[39mDATA_URL \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhotdog.zip\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      3\u001B[0m                          \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfba480ffa8aa7e0febbb511d181409f899b9baa5\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m data_dir \u001B[38;5;241m=\u001B[39m \u001B[43md2l\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_extract\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhotdog\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/site-packages/d2l/torch.py:399\u001B[0m, in \u001B[0;36mdownload_extract\u001B[0;34m(name, folder)\u001B[0m\n\u001B[1;32m    395\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdownload_extract\u001B[39m(name, folder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    396\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Download and extract a zip/tar file.\u001B[39;00m\n\u001B[1;32m    397\u001B[0m \n\u001B[1;32m    398\u001B[0m \u001B[38;5;124;03m    Defined in :numref:`sec_kaggle_house`\"\"\"\u001B[39;00m\n\u001B[0;32m--> 399\u001B[0m     fname \u001B[38;5;241m=\u001B[39m \u001B[43mdownload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    400\u001B[0m     base_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mdirname(fname)\n\u001B[1;32m    401\u001B[0m     data_dir, ext \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msplitext(fname)\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/site-packages/d2l/torch.py:392\u001B[0m, in \u001B[0;36mdownload\u001B[0;34m(name, cache_dir)\u001B[0m\n\u001B[1;32m    390\u001B[0m r \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(url, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, verify\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    391\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(fname, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m--> 392\u001B[0m     f\u001B[38;5;241m.\u001B[39mwrite(\u001B[43mr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m)\n\u001B[1;32m    393\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fname\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/site-packages/requests/models.py:899\u001B[0m, in \u001B[0;36mResponse.content\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    897\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    898\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 899\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter_content\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCONTENT_CHUNK_SIZE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content_consumed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    902\u001B[0m \u001B[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001B[39;00m\n\u001B[1;32m    903\u001B[0m \u001B[38;5;66;03m# since we exhausted the data.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/site-packages/requests/models.py:816\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 816\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    817\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    818\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/site-packages/urllib3/response.py:628\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m    626\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp):\n\u001B[0;32m--> 628\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    630\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[1;32m    631\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/site-packages/urllib3/response.py:567\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt, decode_content, cache_content)\u001B[0m\n\u001B[1;32m    564\u001B[0m fp_closed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_error_catcher():\n\u001B[0;32m--> 567\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fp_closed \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    568\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    569\u001B[0m         flush_decoder \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/site-packages/urllib3/response.py:533\u001B[0m, in \u001B[0;36mHTTPResponse._fp_read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m buffer\u001B[38;5;241m.\u001B[39mgetvalue()\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    532\u001B[0m     \u001B[38;5;66;03m# StringIO doesn't like amt=None\u001B[39;00m\n\u001B[0;32m--> 533\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/http/client.py:463\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    460\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    461\u001B[0m     \u001B[38;5;66;03m# Amount is given, implement using readinto\u001B[39;00m\n\u001B[1;32m    462\u001B[0m     b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mbytearray\u001B[39m(amt)\n\u001B[0;32m--> 463\u001B[0m     n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    464\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(b)[:n]\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[1;32m    465\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    466\u001B[0m     \u001B[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001B[39;00m\n\u001B[1;32m    467\u001B[0m     \u001B[38;5;66;03m# and self.chunked\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/http/client.py:507\u001B[0m, in \u001B[0;36mHTTPResponse.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    502\u001B[0m         b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmemoryview\u001B[39m(b)[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength]\n\u001B[1;32m    504\u001B[0m \u001B[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001B[39;00m\n\u001B[1;32m    505\u001B[0m \u001B[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001B[39;00m\n\u001B[1;32m    506\u001B[0m \u001B[38;5;66;03m# (for example, reading in 1k chunks)\u001B[39;00m\n\u001B[0;32m--> 507\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m n \u001B[38;5;129;01mand\u001B[39;00m b:\n\u001B[1;32m    509\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[1;32m    510\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[1;32m    511\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[0;32m~/anaconda3/envs/d2l-zh/lib/python3.9/socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['hotdog'] = (d2l.DATA_URL + 'hotdog.zip',\n",
    "                         'fba480ffa8aa7e0febbb511d181409f899b9baa5')\n",
    "\n",
    "data_dir = d2l.download_extract('hotdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f79cc3",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "我们创建两个实例来分别读取训练和测试数据集中的所有图像文件。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf7f61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:57.320559Z",
     "iopub.status.busy": "2022-12-07T16:37:57.320091Z",
     "iopub.status.idle": "2022-12-07T16:37:57.332319Z",
     "shell.execute_reply": "2022-12-07T16:37:57.331564Z"
    },
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "start_time": "2023-08-20T15:04:54.954860Z"
    }
   },
   "outputs": [],
   "source": [
    "train_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'))\n",
    "test_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3dbe86",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "下面显示了前8个正类样本图片和最后8张负类样本图片。正如所看到的，[**图像的大小和纵横比各有不同**]。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd1ad03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:57.337195Z",
     "iopub.status.busy": "2022-12-07T16:37:57.336741Z",
     "iopub.status.idle": "2022-12-07T16:37:58.109659Z",
     "shell.execute_reply": "2022-12-07T16:37:58.108824Z"
    },
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-08-20T15:04:54.957068Z",
     "start_time": "2023-08-20T15:04:54.955999Z"
    }
   },
   "outputs": [],
   "source": [
    "hotdogs = [train_imgs[i][0] for i in range(8)]\n",
    "not_hotdogs = [train_imgs[-i - 1][0] for i in range(8)]\n",
    "d2l.show_images(hotdogs + not_hotdogs, 2, 8, scale=1.4);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae506fa5",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "在训练期间，我们首先从图像中裁切随机大小和随机长宽比的区域，然后将该区域缩放为$224 \\times 224$输入图像。\n",
    "在测试过程中，我们将图像的高度和宽度都缩放到256像素，然后裁剪中央$224 \\times 224$区域作为输入。\n",
    "此外，对于RGB（红、绿和蓝）颜色通道，我们分别*标准化*每个通道。\n",
    "具体而言，该通道的每个值减去该通道的平均值，然后将结果除以该通道的标准差。\n",
    "\n",
    "[~~数据增广~~]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6610d49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:58.123563Z",
     "iopub.status.busy": "2022-12-07T16:37:58.122794Z",
     "iopub.status.idle": "2022-12-07T16:37:58.129504Z",
     "shell.execute_reply": "2022-12-07T16:37:58.128693Z"
    },
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-08-20T15:04:54.957709Z",
     "start_time": "2023-08-20T15:04:54.957322Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用RGB通道的均值和标准差，以标准化每个通道\n",
    "normalize = torchvision.transforms.Normalize(\n",
    "    [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "train_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "test_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize([256, 256]),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be5b592",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "### [**定义和初始化模型**]\n",
    "\n",
    "我们使用在ImageNet数据集上预训练的ResNet-18作为源模型。\n",
    "在这里，我们指定`pretrained=True`以自动下载预训练的模型参数。\n",
    "如果首次使用此模型，则需要连接互联网才能下载。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63afca77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:58.133958Z",
     "iopub.status.busy": "2022-12-07T16:37:58.133274Z",
     "iopub.status.idle": "2022-12-07T16:37:58.407434Z",
     "shell.execute_reply": "2022-12-07T16:37:58.406531Z"
    },
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-08-20T15:04:54.959505Z",
     "start_time": "2023-08-20T15:04:54.958387Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_net = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31546d8d",
   "metadata": {
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "预训练的源模型实例包含许多特征层和一个输出层`fc`。\n",
    "此划分的主要目的是促进对除输出层以外所有层的模型参数进行微调。\n",
    "下面给出了源模型的成员变量`fc`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb9025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:58.412929Z",
     "iopub.status.busy": "2022-12-07T16:37:58.412442Z",
     "iopub.status.idle": "2022-12-07T16:37:58.418165Z",
     "shell.execute_reply": "2022-12-07T16:37:58.417415Z"
    },
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-08-20T15:04:54.960184Z",
     "start_time": "2023-08-20T15:04:54.959552Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_net.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585783fb",
   "metadata": {
    "origin_pos": 25
   },
   "source": [
    "在ResNet的全局平均汇聚层后，全连接层转换为ImageNet数据集的1000个类输出。\n",
    "之后，我们构建一个新的神经网络作为目标模型。\n",
    "它的定义方式与预训练源模型的定义方式相同，只是最终层中的输出数量被设置为目标数据集中的类数（而不是1000个）。\n",
    "\n",
    "在下面的代码中，目标模型`finetune_net`中成员变量`features`的参数被初始化为源模型相应层的模型参数。\n",
    "由于模型参数是在ImageNet数据集上预训练的，并且足够好，因此通常只需要较小的学习率即可微调这些参数。\n",
    "\n",
    "成员变量`output`的参数是随机初始化的，通常需要更高的学习率才能从头开始训练。\n",
    "假设`Trainer`实例中的学习率为$\\eta$，我们将成员变量`output`中参数的学习率设置为$10\\eta$。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43500069",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:58.422637Z",
     "iopub.status.busy": "2022-12-07T16:37:58.422074Z",
     "iopub.status.idle": "2022-12-07T16:37:58.669492Z",
     "shell.execute_reply": "2022-12-07T16:37:58.668626Z"
    },
    "origin_pos": 27,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "start_time": "2023-08-20T15:04:54.960711Z"
    }
   },
   "outputs": [],
   "source": [
    "finetune_net = torchvision.models.resnet18(pretrained=True)\n",
    "finetune_net.fc = nn.Linear(finetune_net.fc.in_features, 2)\n",
    "nn.init.xavier_uniform_(finetune_net.fc.weight);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49531348",
   "metadata": {
    "origin_pos": 29
   },
   "source": [
    "### [**微调模型**]\n",
    "\n",
    "首先，我们定义了一个训练函数`train_fine_tuning`，该函数使用微调，因此可以多次调用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3e101",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:58.674339Z",
     "iopub.status.busy": "2022-12-07T16:37:58.673792Z",
     "iopub.status.idle": "2022-12-07T16:37:58.681528Z",
     "shell.execute_reply": "2022-12-07T16:37:58.680703Z"
    },
    "origin_pos": 31,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "start_time": "2023-08-20T15:04:54.961685Z"
    }
   },
   "outputs": [],
   "source": [
    "# 如果param_group=True，输出层中的模型参数将使用十倍的学习率\n",
    "def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=5,\n",
    "                      param_group=True):\n",
    "    train_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'train'), transform=train_augs),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'test'), transform=test_augs),\n",
    "        batch_size=batch_size)\n",
    "    devices = d2l.try_all_gpus()\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    if param_group:\n",
    "        params_1x = [param for name, param in net.named_parameters()\n",
    "             if name not in [\"fc.weight\", \"fc.bias\"]]\n",
    "        trainer = torch.optim.SGD([{'params': params_1x},\n",
    "                                   {'params': net.fc.parameters(),\n",
    "                                    'lr': learning_rate * 10}],\n",
    "                                lr=learning_rate, weight_decay=0.001)\n",
    "    else:\n",
    "        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate,\n",
    "                                  weight_decay=0.001)\n",
    "    d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,\n",
    "                   devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0944654",
   "metadata": {
    "origin_pos": 33
   },
   "source": [
    "我们[**使用较小的学习率**]，通过*微调*预训练获得的模型参数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca4ef19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:58.685559Z",
     "iopub.status.busy": "2022-12-07T16:37:58.684806Z",
     "iopub.status.idle": "2022-12-07T16:39:23.696907Z",
     "shell.execute_reply": "2022-12-07T16:39:23.696074Z"
    },
    "origin_pos": 35,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "start_time": "2023-08-20T15:04:54.962436Z"
    }
   },
   "outputs": [],
   "source": [
    "train_fine_tuning(finetune_net, 5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a04d31e",
   "metadata": {
    "origin_pos": 36
   },
   "source": [
    "[**为了进行比较，**]我们定义了一个相同的模型，但是将其(**所有模型参数初始化为随机值**)。\n",
    "由于整个模型需要从头开始训练，因此我们需要使用更大的学习率。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ea239",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:39:23.702375Z",
     "iopub.status.busy": "2022-12-07T16:39:23.701792Z",
     "iopub.status.idle": "2022-12-07T16:40:45.446588Z",
     "shell.execute_reply": "2022-12-07T16:40:45.445443Z"
    },
    "origin_pos": 38,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-08-20T15:04:54.963343Z",
     "start_time": "2023-08-20T15:04:54.963033Z"
    }
   },
   "outputs": [],
   "source": [
    "scratch_net = torchvision.models.resnet18()\n",
    "scratch_net.fc = nn.Linear(scratch_net.fc.in_features, 2)\n",
    "train_fine_tuning(scratch_net, 5e-4, param_group=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e371a53",
   "metadata": {
    "origin_pos": 40
   },
   "source": [
    "意料之中，微调模型往往表现更好，因为它的初始参数值更有效。\n",
    "\n",
    "## 小结\n",
    "\n",
    "* 迁移学习将从源数据集中学到的知识*迁移*到目标数据集，微调是迁移学习的常见技巧。\n",
    "* 除输出层外，目标模型从源模型中复制所有模型设计及其参数，并根据目标数据集对这些参数进行微调。但是，目标模型的输出层需要从头开始训练。\n",
    "* 通常，微调参数使用较小的学习率，而从头开始训练输出层可以使用更大的学习率。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 继续提高`finetune_net`的学习率，模型的准确性如何变化？\n",
    "2. 在比较实验中进一步调整`finetune_net`和`scratch_net`的超参数。它们的准确性还有不同吗？\n",
    "3. 将输出层`finetune_net`之前的参数设置为源模型的参数，在训练期间不要更新它们。模型的准确性如何变化？提示：可以使用以下代码。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19433761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:40:45.450383Z",
     "iopub.status.busy": "2022-12-07T16:40:45.449520Z",
     "iopub.status.idle": "2022-12-07T16:40:45.455316Z",
     "shell.execute_reply": "2022-12-07T16:40:45.453890Z"
    },
    "origin_pos": 42,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "start_time": "2023-08-20T15:04:54.963630Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in finetune_net.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9107a0",
   "metadata": {
    "origin_pos": 44
   },
   "source": [
    "4. 事实上，`ImageNet`数据集中有一个“热狗”类别。我们可以通过以下代码获取其输出层中的相应权重参数，但是我们怎样才能利用这个权重参数？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03889099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:40:45.460528Z",
     "iopub.status.busy": "2022-12-07T16:40:45.459409Z",
     "iopub.status.idle": "2022-12-07T16:40:45.472096Z",
     "shell.execute_reply": "2022-12-07T16:40:45.470704Z"
    },
    "origin_pos": 46,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "start_time": "2023-08-20T15:04:54.964190Z"
    }
   },
   "outputs": [],
   "source": [
    "weight = pretrained_net.fc.weight\n",
    "hotdog_w = torch.split(weight.data, 1, dim=0)[934]\n",
    "hotdog_w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa964d",
   "metadata": {
    "origin_pos": 49,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/2894)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
